{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:33.351777Z",
     "start_time": "2023-12-03T19:56:33.335723800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from kafka import KafkaConsumer\n",
    "#from skmultiflow.drift_detection import DDM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# implement basic ddm change detector\n",
    "class DDM:\n",
    "    \"\"\" Drift Detection Method for evolving data streams.\"\"\"\n",
    "    \n",
    "    def __init__(self, min_num_instances=30, warning_level=2.0, out_control_level=3.0):\n",
    "        \"\"\" Init DDM.\"\"\"\n",
    "        self.min_num_instances = min_num_instances\n",
    "        self.warning_level = warning_level\n",
    "        self.out_control_level = out_control_level\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Reset the change detector.\"\"\"\n",
    "        self.n = 1\n",
    "        self.m_n = 0\n",
    "        self.s_n = 0\n",
    "        self.m_n1 = 0\n",
    "        self.s_n1 = 0\n",
    "        self.min_num_instances = 30\n",
    "        self.warning_level = 2.0\n",
    "        self.out_control_level = 3.0\n",
    "        self.in_concept_change = False\n",
    "        self.in_warning_zone = False\n",
    "\n",
    "    def add_element(self, value):\n",
    "        \"\"\" Add a new element to the statistics. \"\"\"\n",
    "        if self.n == 1:\n",
    "            self.m_n = value\n",
    "            self.s_n = 0\n",
    "        else:\n",
    "            self.m_n1 = self.m_n\n",
    "            self.s_n1 = self.s_n\n",
    "            self.m_n = self.m_n1 + (value - self.m_n1) / self.n\n",
    "            self.s_n = self.s_n1 + (value - self.m_n1) * (value - self.m_n)\n",
    "\n",
    "        self.n += 1\n",
    "\n",
    "        if self.n < self.min_num_instances:\n",
    "            return 1\n",
    "\n",
    "        if self.s_n < 0:\n",
    "            self.s_n = 0\n",
    "\n",
    "        if self.s_n > 0:\n",
    "            z_n = (value - self.m_n) / (self.s_n ** 0.5)\n",
    "        else:\n",
    "            z_n = 0\n",
    "\n",
    "        if z_n < self.warning_level:\n",
    "            self.in_warning_zone = True\n",
    "        else:\n",
    "            self.in_warning_zone = False\n",
    "\n",
    "        if z_n < self.out_control_level:\n",
    "            self.in_concept_change = True\n",
    "        else:\n",
    "            self.in_concept_change = False\n",
    "\n",
    "        return z_n\n",
    "\n",
    "    def get_info(self):\n",
    "        \"\"\"Return information about the change.\"\"\"\n",
    "        description = \"DDM: Drift Detection Method for evolving data streams.\\n\"\n",
    "        description += \"min_num_instances: \" + str(self.min_num_instances) + \"\\n\"\n",
    "        description += \"warning_level: \" + str(self.warning_level) + \"\\n\"\n",
    "        description += \"out_control_level: \" + str(self.out_control_level)\n",
    "        return description\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:33.745034600Z",
     "start_time": "2023-12-03T19:56:33.735310400Z"
    }
   },
   "id": "484ffb2a5aa88789"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# import csv training data\n",
    "data_folder = '../../hai_dataset/hai/hai-21.03'\n",
    "data_filename = 'train1.csv'\n",
    "data_path = os.path.join(data_folder, data_filename).replace(os.sep, '/')\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "# data columns\n",
    "\n",
    "# timestamp is the time of the event\n",
    "# there are multiple features\n",
    "# the label columns are "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:36.892427100Z",
     "start_time": "2023-12-03T19:56:36.042545100Z"
    }
   },
   "id": "82ae94dd94c0ddbc"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "label_columns = ['attack', 'attack_P1', 'attack_P2', 'attack_P3']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(label_columns, axis=1), df[label_columns], test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:39.993399700Z",
     "start_time": "2023-12-03T19:56:39.852238100Z"
    }
   },
   "id": "31ad2cdcbef1dd01"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                     P1_B2004  P1_B2016   P1_B3004    P1_B3005  P1_B4002  \\\ntime                                                                       \n2020-07-11 09:03:09   0.09913   1.41187  396.71945   894.71869  32.00000   \n2020-07-11 17:51:08   0.09933   1.42565  394.01361  1055.10217  32.38132   \n2020-07-12 17:38:52   0.09841   1.33974  406.22626   961.54413  33.52099   \n2020-07-13 07:19:37   0.09904   1.35274  399.73972  1085.01001  31.64864   \n2020-07-12 10:03:01   0.10135   1.31842  406.68262   902.40576  32.00000   \n\n                      P1_B4005    P1_B400B  P1_B4022  P1_FCV01D  P1_FCV01Z  \\\ntime                                                                         \n2020-07-11 09:03:09   50.06480  1555.60352  35.78186   17.42988   16.32843   \n2020-07-11 17:51:08  100.00000  2825.40674  36.19713  100.00000   99.49343   \n2020-07-12 17:38:52  100.00000  2832.28540  37.12432  100.00000   99.30044   \n2020-07-13 07:19:37   33.09878  1126.19263  35.28287   14.49461   16.06903   \n2020-07-12 10:03:01   34.67972  1052.52466  35.54268   15.99286   14.68811   \n\n                     ...  P4_HT_PO  P4_HT_PS      P4_LD  P4_ST_FD  P4_ST_GOV  \\\ntime                 ...                                                       \n2020-07-11 09:03:09  ...   6.69128         0  345.75738  -0.00130    18264.0   \n2020-07-11 17:51:08  ...  69.93268         0  380.80512   0.00217    18081.0   \n2020-07-12 17:38:52  ...   0.30743         0  360.33350   0.00101    17610.0   \n2020-07-13 07:19:37  ...   0.47021         0  305.73645  -0.00015    17084.0   \n2020-07-12 10:03:01  ...   0.05423         0  336.58856   0.00015    17172.0   \n\n                      P4_ST_LD   P4_ST_PO  P4_ST_PS  P4_ST_PT01  P4_ST_TT01  \ntime                                                                         \n2020-07-11 09:03:09  347.05951  339.35547         0     10086.0     27612.0  \n2020-07-11 17:51:08  312.86169  336.51617         0     10053.0     27582.0  \n2020-07-12 17:38:52  360.96643  324.68896         0     10026.0     27578.0  \n2020-07-13 07:19:37  304.16303  317.05731         0     10052.0     27596.0  \n2020-07-12 10:03:01  338.59595  315.97223         0      9999.0     27613.0  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P1_B2004</th>\n      <th>P1_B2016</th>\n      <th>P1_B3004</th>\n      <th>P1_B3005</th>\n      <th>P1_B4002</th>\n      <th>P1_B4005</th>\n      <th>P1_B400B</th>\n      <th>P1_B4022</th>\n      <th>P1_FCV01D</th>\n      <th>P1_FCV01Z</th>\n      <th>...</th>\n      <th>P4_HT_PO</th>\n      <th>P4_HT_PS</th>\n      <th>P4_LD</th>\n      <th>P4_ST_FD</th>\n      <th>P4_ST_GOV</th>\n      <th>P4_ST_LD</th>\n      <th>P4_ST_PO</th>\n      <th>P4_ST_PS</th>\n      <th>P4_ST_PT01</th>\n      <th>P4_ST_TT01</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-07-11 09:03:09</th>\n      <td>0.09913</td>\n      <td>1.41187</td>\n      <td>396.71945</td>\n      <td>894.71869</td>\n      <td>32.00000</td>\n      <td>50.06480</td>\n      <td>1555.60352</td>\n      <td>35.78186</td>\n      <td>17.42988</td>\n      <td>16.32843</td>\n      <td>...</td>\n      <td>6.69128</td>\n      <td>0</td>\n      <td>345.75738</td>\n      <td>-0.00130</td>\n      <td>18264.0</td>\n      <td>347.05951</td>\n      <td>339.35547</td>\n      <td>0</td>\n      <td>10086.0</td>\n      <td>27612.0</td>\n    </tr>\n    <tr>\n      <th>2020-07-11 17:51:08</th>\n      <td>0.09933</td>\n      <td>1.42565</td>\n      <td>394.01361</td>\n      <td>1055.10217</td>\n      <td>32.38132</td>\n      <td>100.00000</td>\n      <td>2825.40674</td>\n      <td>36.19713</td>\n      <td>100.00000</td>\n      <td>99.49343</td>\n      <td>...</td>\n      <td>69.93268</td>\n      <td>0</td>\n      <td>380.80512</td>\n      <td>0.00217</td>\n      <td>18081.0</td>\n      <td>312.86169</td>\n      <td>336.51617</td>\n      <td>0</td>\n      <td>10053.0</td>\n      <td>27582.0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12 17:38:52</th>\n      <td>0.09841</td>\n      <td>1.33974</td>\n      <td>406.22626</td>\n      <td>961.54413</td>\n      <td>33.52099</td>\n      <td>100.00000</td>\n      <td>2832.28540</td>\n      <td>37.12432</td>\n      <td>100.00000</td>\n      <td>99.30044</td>\n      <td>...</td>\n      <td>0.30743</td>\n      <td>0</td>\n      <td>360.33350</td>\n      <td>0.00101</td>\n      <td>17610.0</td>\n      <td>360.96643</td>\n      <td>324.68896</td>\n      <td>0</td>\n      <td>10026.0</td>\n      <td>27578.0</td>\n    </tr>\n    <tr>\n      <th>2020-07-13 07:19:37</th>\n      <td>0.09904</td>\n      <td>1.35274</td>\n      <td>399.73972</td>\n      <td>1085.01001</td>\n      <td>31.64864</td>\n      <td>33.09878</td>\n      <td>1126.19263</td>\n      <td>35.28287</td>\n      <td>14.49461</td>\n      <td>16.06903</td>\n      <td>...</td>\n      <td>0.47021</td>\n      <td>0</td>\n      <td>305.73645</td>\n      <td>-0.00015</td>\n      <td>17084.0</td>\n      <td>304.16303</td>\n      <td>317.05731</td>\n      <td>0</td>\n      <td>10052.0</td>\n      <td>27596.0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12 10:03:01</th>\n      <td>0.10135</td>\n      <td>1.31842</td>\n      <td>406.68262</td>\n      <td>902.40576</td>\n      <td>32.00000</td>\n      <td>34.67972</td>\n      <td>1052.52466</td>\n      <td>35.54268</td>\n      <td>15.99286</td>\n      <td>14.68811</td>\n      <td>...</td>\n      <td>0.05423</td>\n      <td>0</td>\n      <td>336.58856</td>\n      <td>0.00015</td>\n      <td>17172.0</td>\n      <td>338.59595</td>\n      <td>315.97223</td>\n      <td>0</td>\n      <td>9999.0</td>\n      <td>27613.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:40.788103800Z",
     "start_time": "2023-12-03T19:56:40.762701800Z"
    }
   },
   "id": "b5bbaabb5584011"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                     attack  attack_P1  attack_P2  attack_P3\ntime                                                        \n2020-07-11 09:03:09       0          0          0          0\n2020-07-11 17:51:08       0          0          0          0\n2020-07-12 17:38:52       0          0          0          0\n2020-07-13 07:19:37       0          0          0          0\n2020-07-12 10:03:01       0          0          0          0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attack</th>\n      <th>attack_P1</th>\n      <th>attack_P2</th>\n      <th>attack_P3</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-07-11 09:03:09</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-11 17:51:08</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12 17:38:52</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-13 07:19:37</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12 10:03:01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:41.699276400Z",
     "start_time": "2023-12-03T19:56:41.680022500Z"
    }
   },
   "id": "a2797e60f7f9910a"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# initialize classifier\n",
    "clf = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:42.578852900Z",
     "start_time": "2023-12-03T19:56:42.562341200Z"
    }
   },
   "id": "1234c2a14feb9bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the initial training\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:45.557880100Z",
     "start_time": "2023-12-03T19:56:43.101464800Z"
    }
   },
   "id": "bbe43d8c6a09d16d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the initial accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:45.730976200Z",
     "start_time": "2023-12-03T19:56:45.559841100Z"
    }
   },
   "id": "e1fa91a80c425c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# connect to kafka\n",
    "consumer = KafkaConsumer('hai-input', bootstrap_servers=['localhost:9092'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:48.735770600Z",
     "start_time": "2023-12-03T19:56:48.603954900Z"
    }
   },
   "id": "b91f4d102fcecd83"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# initialize drift detector\n",
    "ddm = DDM()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T19:56:49.077239100Z",
     "start_time": "2023-12-03T19:56:49.069094300Z"
    }
   },
   "id": "99415c1097d08ee3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def split_dict(data_dict, label_keys):\n",
    "    \"\"\"\n",
    "    Split a dictionary into two dictionaries based on the specified keys.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dict (dict): The input dictionary.\n",
    "    - keys (list): List of keys to include in the first dictionary.\n",
    "\n",
    "    Returns:\n",
    "    - dict, dict: Two dictionaries - one with specified keys, and one with the rest.\n",
    "    \"\"\"\n",
    "    selected_dict = {key: data_dict[key] for key in label_keys if key in data_dict}\n",
    "    remaining_dict = {key: data_dict[key] for key in data_dict if key not in label_keys}\n",
    "    return remaining_dict, selected_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:04:26.690337900Z",
     "start_time": "2023-12-03T20:04:26.679316700Z"
    }
   },
   "id": "df6e3c95b839bec6"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# consume the streamed data from kafka and detect drift\u001B[39;00m\n\u001B[0;32m      2\u001B[0m label_columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack_P1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack_P2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack_P3\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m msg \u001B[38;5;129;01min\u001B[39;00m consumer:\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# get the data\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(msg\u001B[38;5;241m.\u001B[39mvalue)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data)\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:1193\u001B[0m, in \u001B[0;36mKafkaConsumer.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_v1()\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:1201\u001B[0m, in \u001B[0;36mKafkaConsumer.next_v2\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_generator_v2()\n\u001B[0;32m   1200\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m   1203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:1116\u001B[0m, in \u001B[0;36mKafkaConsumer._message_generator_v2\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_message_generator_v2\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1115\u001B[0m     timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consumer_timeout \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mtime())\n\u001B[1;32m-> 1116\u001B[0m     record_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tp, records \u001B[38;5;129;01min\u001B[39;00m six\u001B[38;5;241m.\u001B[39miteritems(record_map):\n\u001B[0;32m   1118\u001B[0m         \u001B[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001B[39;00m\n\u001B[0;32m   1119\u001B[0m         \u001B[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001B[39;00m\n\u001B[0;32m   1120\u001B[0m         \u001B[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m records:\n\u001B[0;32m   1122\u001B[0m             \u001B[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001B[39;00m\n\u001B[0;32m   1123\u001B[0m             \u001B[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001B[39;00m\n\u001B[0;32m   1124\u001B[0m             \u001B[38;5;66;03m# outer function destroying the existing iterator/generator\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m             \u001B[38;5;66;03m# via self._iterator = None\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:655\u001B[0m, in \u001B[0;36mKafkaConsumer.poll\u001B[1;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[0;32m    653\u001B[0m remaining \u001B[38;5;241m=\u001B[39m timeout_ms\n\u001B[0;32m    654\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 655\u001B[0m     records \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_records\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupdate_offsets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m records:\n\u001B[0;32m    657\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m records\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:702\u001B[0m, in \u001B[0;36mKafkaConsumer._poll_once\u001B[1;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mpoll(timeout_ms\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    701\u001B[0m timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout_ms, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mtime_to_next_poll() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m--> 702\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001B[39;00m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001B[39;00m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mneed_rejoin():\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\client_async.py:602\u001B[0m, in \u001B[0;36mKafkaClient.poll\u001B[1;34m(self, timeout_ms, future)\u001B[0m\n\u001B[0;32m    599\u001B[0m             timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mretry_backoff_ms\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    600\u001B[0m         timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, timeout)  \u001B[38;5;66;03m# avoid negative timeouts\u001B[39;00m\n\u001B[1;32m--> 602\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# called without the lock to avoid deadlock potential\u001B[39;00m\n\u001B[0;32m    605\u001B[0m \u001B[38;5;66;03m# if handlers need to acquire locks\u001B[39;00m\n\u001B[0;32m    606\u001B[0m responses\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_pending_completed_requests())\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\client_async.py:634\u001B[0m, in \u001B[0;36mKafkaClient._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register_send_sockets()\n\u001B[0;32m    633\u001B[0m start_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 634\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    635\u001B[0m end_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sensors:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\selectors.py:324\u001B[0m, in \u001B[0;36mSelectSelector.select\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    322\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 324\u001B[0m     r, w, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_readers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_writers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\selectors.py:315\u001B[0m, in \u001B[0;36mSelectSelector._select\u001B[1;34m(self, r, w, _, timeout)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_select\u001B[39m(\u001B[38;5;28mself\u001B[39m, r, w, _, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 315\u001B[0m     r, w, x \u001B[38;5;241m=\u001B[39m \u001B[43mselect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m r, w \u001B[38;5;241m+\u001B[39m x, []\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# consume the streamed data from kafka and detect drift\n",
    "label_columns = ['attack', 'attack_P1', 'attack_P2', 'attack_P3']\n",
    "for msg in consumer:\n",
    "    # get the data\n",
    "    data = json.loads(msg.value)\n",
    "    print(data)\n",
    "    # get the timestamp\n",
    "    timestamp = datetime.fromtimestamp(data.drop(['time']))\n",
    "    # get the features\n",
    "    features, label = split_dict(data, label_columns)\n",
    "    print(features, label)\n",
    "    # get the label\n",
    "    # add the data to the classifier\n",
    "    #clf.partial_fit(features, label)\n",
    "    # get the prediction\n",
    "    y_pred = clf.predict(features)\n",
    "    # get the accuracy\n",
    "    accuracy = accuracy_score(label, y_pred)\n",
    "    # add the data to the drift detector\n",
    "    ddm.add_element(accuracy)\n",
    "    # get the drift status\n",
    "    drift_status = ddm.get_info()\n",
    "    # print the results\n",
    "    print(f'{timestamp} - {accuracy} - {drift_status}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:05:30.649918400Z",
     "start_time": "2023-12-03T20:04:33.059279200Z"
    }
   },
   "id": "91b44ebf083030a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "25dec58a90558dc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
