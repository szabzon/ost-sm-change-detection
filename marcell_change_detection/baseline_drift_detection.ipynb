{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-04T16:50:50.228614400Z",
     "start_time": "2023-12-04T16:50:50.217571600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from kafka import KafkaConsumer\n",
    "#from skmultiflow.drift_detection import DDM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# import csv training data\n",
    "data_folder = '../../hai_dataset/hai/hai-21.03'\n",
    "data_filename = 'train1.csv'\n",
    "data_path = os.path.join(data_folder, data_filename).replace(os.sep, '/')\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "# data columns\n",
    "\n",
    "# timestamp is the time of the event\n",
    "# there are multiple features\n",
    "# the label columns are "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:15:26.738184900Z",
     "start_time": "2023-12-04T17:15:25.848411400Z"
    }
   },
   "id": "82ae94dd94c0ddbc"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "label_columns = ['attack', 'attack_P1', 'attack_P2', 'attack_P3']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(label_columns, axis=1), df[label_columns], test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:01:00.529606Z",
     "start_time": "2023-12-04T17:01:00.400403900Z"
    }
   },
   "id": "31ad2cdcbef1dd01"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P1_B2004', 'P1_B2016', 'P1_B3004', 'P1_B3005', 'P1_B4002', 'P1_B4005', 'P1_B400B', 'P1_B4022', 'P1_FCV01D', 'P1_FCV01Z', 'P1_FCV02D', 'P1_FCV02Z', 'P1_FCV03D', 'P1_FCV03Z', 'P1_FT01', 'P1_FT01Z', 'P1_FT02', 'P1_FT02Z', 'P1_FT03', 'P1_FT03Z', 'P1_LCV01D', 'P1_LCV01Z', 'P1_LIT01', 'P1_PCV01D', 'P1_PCV01Z', 'P1_PCV02D', 'P1_PCV02Z', 'P1_PIT01', 'P1_PIT02', 'P1_PP01AD', 'P1_PP01AR', 'P1_PP01BD', 'P1_PP01BR', 'P1_PP02D', 'P1_PP02R', 'P1_STSP', 'P1_TIT01', 'P1_TIT02', 'P2_24Vdc', 'P2_ASD', 'P2_AutoGO', 'P2_CO_rpm', 'P2_Emerg', 'P2_HILout', 'P2_MSD', 'P2_ManualGO', 'P2_OnOff', 'P2_RTR', 'P2_SIT01', 'P2_SIT02', 'P2_TripEx', 'P2_VT01', 'P2_VTR01', 'P2_VTR02', 'P2_VTR03', 'P2_VTR04', 'P2_VXT02', 'P2_VXT03', 'P2_VYT02', 'P2_VYT03', 'P3_FIT01', 'P3_LCP01D', 'P3_LCV01D', 'P3_LH', 'P3_LIT01', 'P3_LL', 'P3_PIT01', 'P4_HT_FD', 'P4_HT_LD', 'P4_HT_PO', 'P4_HT_PS', 'P4_LD', 'P4_ST_FD', 'P4_ST_GOV', 'P4_ST_LD', 'P4_ST_PO', 'P4_ST_PS', 'P4_ST_PT01', 'P4_ST_TT01']\n"
     ]
    }
   ],
   "source": [
    "# save the column names to a list\n",
    "column_names = X_train.columns.tolist()\n",
    "print(column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:01:01.551820500Z",
     "start_time": "2023-12-04T17:01:01.548208200Z"
    }
   },
   "id": "b5bbaabb5584011"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "                     attack  attack_P1  attack_P2  attack_P3\ntime                                                        \n2020-07-11 09:03:09       0          0          0          0\n2020-07-11 17:51:08       0          0          0          0\n2020-07-12 17:38:52       0          0          0          0\n2020-07-13 07:19:37       0          0          0          0\n2020-07-12 10:03:01       0          0          0          0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attack</th>\n      <th>attack_P1</th>\n      <th>attack_P2</th>\n      <th>attack_P3</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-07-11 09:03:09</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-11 17:51:08</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12 17:38:52</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-13 07:19:37</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12 10:03:01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:01:01.878240500Z",
     "start_time": "2023-12-04T17:01:01.859275900Z"
    }
   },
   "id": "a2797e60f7f9910a"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# initialize classifier\n",
    "clf = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:01:02.113462300Z",
     "start_time": "2023-12-04T17:01:02.097851600Z"
    }
   },
   "id": "1234c2a14feb9bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()",
      "text/html": "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the initial training\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:01:04.781584200Z",
     "start_time": "2023-12-04T17:01:02.318325500Z"
    }
   },
   "id": "bbe43d8c6a09d16d"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the initial accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:01:04.942891800Z",
     "start_time": "2023-12-04T17:01:04.781584200Z"
    }
   },
   "id": "e1fa91a80c425c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# implement basic ddm change detector\n",
    "class DDM:\n",
    "    \"\"\" Drift Detection Method for evolving data streams.\"\"\"\n",
    "    \n",
    "    def __init__(self, min_num_instances=30, warning_level=2.0, out_control_level=3.0):\n",
    "        \"\"\" Init DDM.\"\"\"\n",
    "        self.min_num_instances = min_num_instances\n",
    "        self.warning_level = warning_level\n",
    "        self.out_control_level = out_control_level\n",
    "        self.reset()\n",
    "        self.mean = 0.0\n",
    "        self.n = 1\n",
    "        self.sum = 0.0\n",
    "        self.buffer = []\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Reset the change detector.\"\"\"\n",
    "        self.n = 1 # number of samples\n",
    "        self.sum = 0.0 # sum of samples\n",
    "        self.mean = 0.0 # mean of samples\n",
    "        self.buffer = [] # buffer of samples\n",
    "        \n",
    "        print('reset')\n",
    "\n",
    "    def add_element(self, value):\n",
    "        \"\"\" Add a new element to the statistics. \"\"\"\n",
    "        # maintain a window of 1000 samples\n",
    "        # if the window is full, remove the oldest sample\n",
    "        # add the new sample\n",
    "        # calculate the average accuracy\n",
    "        # if the average accuracy is less than 0.5, then we detect a change\n",
    "        # return the change status\n",
    "        \n",
    "        # if the window is full, remove the oldest sample\n",
    "        if self.n > self.min_num_instances:\n",
    "            self.sum -= self.buffer.pop(0)\n",
    "        else:\n",
    "            self.n += 1\n",
    "            \n",
    "        # add the new sample\n",
    "        self.buffer.append(value)\n",
    "        self.sum += value\n",
    "        self.mean = self.sum / self.n\n",
    "        \n",
    "        return self.mean\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    def get_info(self):\n",
    "        \"\"\"Return information about the change.\"\"\"\n",
    "        description = \"DDM: Drift Detection Method for evolving data streams.\\n\"\n",
    "        description += \"min_num_instances: \" + str(self.min_num_instances) + \"\\n\"\n",
    "        description += \"warning_level: \" + str(self.warning_level) + \"\\n\"\n",
    "        description += \"out_control_level: \" + str(self.out_control_level)\n",
    "        return description \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:16:06.221640200Z",
     "start_time": "2023-12-04T17:16:06.208388900Z"
    }
   },
   "id": "484ffb2a5aa88789"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "class StreamConsumer:\n",
    "    def __init__(self, topic, bootstrap_servers):\n",
    "        self.topic = topic\n",
    "        self.bootstrap_servers = bootstrap_servers\n",
    "        self.consumer = KafkaConsumer(\n",
    "            self.topic,\n",
    "            bootstrap_servers=self.bootstrap_servers,\n",
    "            auto_offset_reset='earliest',\n",
    "            enable_auto_commit=True,\n",
    "            value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "    def consume_next(self):\n",
    "        # consume the next message\n",
    "        return next(self.consumer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:16:11.472498700Z",
     "start_time": "2023-12-04T17:16:11.458037300Z"
    }
   },
   "id": "fe3c2d1485c8f52a"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "topic = 'hai-preprocessed'\n",
    "bootstrap_servers = ['localhost:9092']\n",
    "consumer = StreamConsumer(topic, bootstrap_servers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:16:12.072769700Z",
     "start_time": "2023-12-04T17:16:11.948468300Z"
    }
   },
   "id": "6acd82af6f73ce1"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n"
     ]
    }
   ],
   "source": [
    "# initialize drift detector\n",
    "ddm = DDM()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:16:12.260827900Z",
     "start_time": "2023-12-04T17:16:12.248205700Z"
    }
   },
   "id": "99415c1097d08ee3"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[144], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# consume the streamed data from kafka and detect drift\u001B[39;00m\n\u001B[0;32m      2\u001B[0m label_columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack_P1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack_P2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattack_P3\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 3\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[43mconsumer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconsume_next\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m msg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# get the next message\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[130], line 13\u001B[0m, in \u001B[0;36mStreamConsumer.consume_next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconsume_next\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# consume the next message\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconsumer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:1193\u001B[0m, in \u001B[0;36mKafkaConsumer.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_v1()\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:1201\u001B[0m, in \u001B[0;36mKafkaConsumer.next_v2\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_generator_v2()\n\u001B[0;32m   1200\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m   1203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:1116\u001B[0m, in \u001B[0;36mKafkaConsumer._message_generator_v2\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_message_generator_v2\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1115\u001B[0m     timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consumer_timeout \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mtime())\n\u001B[1;32m-> 1116\u001B[0m     record_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tp, records \u001B[38;5;129;01min\u001B[39;00m six\u001B[38;5;241m.\u001B[39miteritems(record_map):\n\u001B[0;32m   1118\u001B[0m         \u001B[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001B[39;00m\n\u001B[0;32m   1119\u001B[0m         \u001B[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001B[39;00m\n\u001B[0;32m   1120\u001B[0m         \u001B[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m records:\n\u001B[0;32m   1122\u001B[0m             \u001B[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001B[39;00m\n\u001B[0;32m   1123\u001B[0m             \u001B[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001B[39;00m\n\u001B[0;32m   1124\u001B[0m             \u001B[38;5;66;03m# outer function destroying the existing iterator/generator\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m             \u001B[38;5;66;03m# via self._iterator = None\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:655\u001B[0m, in \u001B[0;36mKafkaConsumer.poll\u001B[1;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[0;32m    653\u001B[0m remaining \u001B[38;5;241m=\u001B[39m timeout_ms\n\u001B[0;32m    654\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 655\u001B[0m     records \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_records\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupdate_offsets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m records:\n\u001B[0;32m    657\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m records\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\consumer\\group.py:702\u001B[0m, in \u001B[0;36mKafkaConsumer._poll_once\u001B[1;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mpoll(timeout_ms\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    701\u001B[0m timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout_ms, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mtime_to_next_poll() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m--> 702\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001B[39;00m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001B[39;00m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mneed_rejoin():\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\client_async.py:602\u001B[0m, in \u001B[0;36mKafkaClient.poll\u001B[1;34m(self, timeout_ms, future)\u001B[0m\n\u001B[0;32m    599\u001B[0m             timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mretry_backoff_ms\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    600\u001B[0m         timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, timeout)  \u001B[38;5;66;03m# avoid negative timeouts\u001B[39;00m\n\u001B[1;32m--> 602\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# called without the lock to avoid deadlock potential\u001B[39;00m\n\u001B[0;32m    605\u001B[0m \u001B[38;5;66;03m# if handlers need to acquire locks\u001B[39;00m\n\u001B[0;32m    606\u001B[0m responses\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_pending_completed_requests())\n",
      "File \u001B[1;32m~\\Documents\\Egyetem\\Open Source Technologies\\ost-sm-change-detection\\venv\\lib\\site-packages\\kafka\\client_async.py:634\u001B[0m, in \u001B[0;36mKafkaClient._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register_send_sockets()\n\u001B[0;32m    633\u001B[0m start_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 634\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    635\u001B[0m end_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sensors:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\selectors.py:324\u001B[0m, in \u001B[0;36mSelectSelector.select\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    322\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 324\u001B[0m     r, w, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_readers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_writers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\selectors.py:315\u001B[0m, in \u001B[0;36mSelectSelector._select\u001B[1;34m(self, r, w, _, timeout)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_select\u001B[39m(\u001B[38;5;28mself\u001B[39m, r, w, _, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 315\u001B[0m     r, w, x \u001B[38;5;241m=\u001B[39m \u001B[43mselect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m r, w \u001B[38;5;241m+\u001B[39m x, []\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# consume the streamed data from kafka and detect drift\n",
    "label_columns = ['attack', 'attack_P1', 'attack_P2', 'attack_P3']\n",
    "msg = consumer.consume_next()\n",
    "i = 0\n",
    "while msg is not None:\n",
    "    # get the next message\n",
    "    msg = consumer.consume_next()\n",
    "    # get the data\n",
    "    data = msg.value\n",
    "    # get the timestamp\n",
    "    timestamp = data.pop('time')\n",
    "    # get the features\n",
    "    features = data.pop('features')\n",
    "    features = pd.DataFrame([features])\n",
    "    # get the label\n",
    "    labels = data.pop('labels')\n",
    "    labels = pd.DataFrame([labels])\n",
    "    # add the data to the classifier\n",
    "    #clf.partial_fit(features, label)\n",
    "    # get the prediction\n",
    "    y_pred = clf.predict(features)\n",
    "    # get the accuracy\n",
    "    accuracy = accuracy_score(labels, y_pred)\n",
    "    # add the data to the drift detector\n",
    "    mean_difference = ddm.add_element(1-accuracy)\n",
    "    #if i > 1000 and (mean_difference > 0.5 or i% 1000 == 0):\n",
    "        # print('mean difference: ', mean_difference)\n",
    "        # reset the drift detector\n",
    "    i += 1\n",
    "    \n",
    "    if accuracy < 0.5:\n",
    "        print('accuracy: ', accuracy)\n",
    "        print('------------------')\n",
    "        \n",
    "    if i % 1000 == 0:\n",
    "        print('mean difference: ', mean_difference)\n",
    "        print('------------------')\n",
    "        ddm.reset()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:25:46.551755900Z",
     "start_time": "2023-12-04T17:25:21.378249400Z"
    }
   },
   "id": "91b44ebf083030a9"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T16:37:29.177889200Z",
     "start_time": "2023-12-04T16:37:29.157714500Z"
    }
   },
   "id": "25dec58a90558dc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "39769820f08d2291"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
