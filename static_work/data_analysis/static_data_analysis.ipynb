{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps and real-time statistical descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"HAI-Preprocessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train1 = spark.read.csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/hai/hai-train1.csv\", header=True, inferSchema=True)\n",
    "train2 = spark.read.csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/hai/hai-train2.csv\", header=True, inferSchema=True)\n",
    "test1 = spark.read.csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/hai/haitest1.csv\", header=True, inferSchema=True)\n",
    "test2 = spark.read.csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/hai/hai-test2.csv\", header=True, inferSchema=True)\n",
    "label1 = spark.read.csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/hai/label-test1.csv\", header=True, inferSchema=True)\n",
    "label2 = spark.read.csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/hai/label-test2.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First input\n",
    "print(f\"First input dimensions: \")\n",
    "print(f\"Train: ({train1.count()}, {len(train1.columns)})\")\n",
    "print(f\"Test: ({test1.count()}, {len(test1.columns)})\")\n",
    "print(f\"Label: ({label1.count()}, {len(label1.columns)})\\n\")\n",
    "\n",
    "# Second input\n",
    "print(f\"Second input dimensions: \")\n",
    "print(f\"Train: ({train2.count()}, {len(train2.columns)})\")\n",
    "print(f\"Test: ({test2.count()}, {len(test2.columns)})\")\n",
    "print(f\"Label: ({label2.count()}, {len(label2.columns)})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts = {}\n",
    "for col_name, col_type in train1.dtypes[1:]:\n",
    "    if col_type in type_counts:\n",
    "        type_counts[col_type].append(col_name)\n",
    "    else:\n",
    "        type_counts[col_type] = [col_name]\n",
    "\n",
    "print(\"Variables by Type:\")\n",
    "for col_type, variables in type_counts.items():\n",
    "    variable_count = len(variables)\n",
    "    print(f\"- {variable_count} {col_type}{'s' if variable_count > 1 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_interval(dataframe):\n",
    "    time_interval = dataframe.agg(min(\"timestamp\").alias(\"start_time\"), max(\"timestamp\").alias(\"end_time\")).collect()[0]\n",
    "\n",
    "    start_time = time_interval[\"start_time\"]\n",
    "    end_time = time_interval[\"end_time\"]\n",
    "\n",
    "    print(f\"Start Time: {start_time}\")\n",
    "    print(f\"End Time: {end_time}\")\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Duration: {duration}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames\n",
    "sets = [train1, test1, train2, test2]\n",
    "sets_name = [\"Train set 1\", \"Test set 1\", \"Train set 2\", \"Test set 2\"]\n",
    "\n",
    "# Calculate time interval and duration for each set\n",
    "for s, set_name in zip(sets, sets_name):\n",
    "    print(f\"=== Time Interval Analysis for {set_name} ===\")\n",
    "    calculate_time_interval(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(dataframe, name=\"DataFrame\"):\n",
    "    print(f\"{name} - Checking for Null Values:\")\n",
    "    \n",
    "    # Calculate the sum of null values for each column\n",
    "    null_counts = dataframe.agg(*[sum(col(c).isNull().cast(\"int\")).alias(c) for c in dataframe.columns]).collect()[0]\n",
    "    \n",
    "    # Iterate over columns and print only if there are null values\n",
    "    found_null_values = False\n",
    "    for col_ in dataframe.columns:\n",
    "        null_count = null_counts[col_]\n",
    "        if null_count > 0:\n",
    "            print(f\"Column '{col_}': {null_count} null values\")\n",
    "            found_null_values = True\n",
    "    \n",
    "    # Print a message if no null values are found\n",
    "    if not found_null_values:\n",
    "        print(f\"No null values found.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values for the first input\n",
    "print(\"FIRST data input\")\n",
    "check_null_values(train1, name=\"Train set\")\n",
    "check_null_values(test1, name=\"Test set\")\n",
    "\n",
    "# Check null values for the second input\n",
    "print(\"\\n\\nSECOND data input\")\n",
    "check_null_values(train2, name=\"Train set\")\n",
    "check_null_values(test2, name=\"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns (excluding timestamp columns)\n",
    "column_subset = [col_ for col_ in train1.columns if train1.select(col_).dtypes[0][1] != \"string\" and col_ != \"timestamp\"]\n",
    "\n",
    "# Impute NaN values with the median for numeric columns\n",
    "imputer = Imputer(\n",
    "    inputCols=column_subset,\n",
    "    outputCols=[col_ for col_ in column_subset],\n",
    "    strategy=\"median\"\n",
    ")\n",
    "\n",
    "# Fit and transform the DataFrame \n",
    "train1 = imputer.fit(train1).transform(train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(dataframe, name=\"DataFrame\"):\n",
    "    found_duplicates = False\n",
    "    \n",
    "    print(f\"{name} - Checking for Duplicates:\")\n",
    "    \n",
    "    # Get the count of each row\n",
    "    row_count = dataframe.count()\n",
    "    \n",
    "    # Get the count of distinct rows\n",
    "    distinct_row_count = dataframe.distinct().count()\n",
    "    \n",
    "    if (row_count - distinct_row_count) > 0:\n",
    "        print(f\"{row_count - distinct_row_count} duplicate rows found.\")\n",
    "        found_duplicates = True\n",
    "    else:\n",
    "        print(f\"No duplicate rows found.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates for the first input\n",
    "print(\"FIRST data input\")\n",
    "check_duplicates(train1, name=\"Train set\")\n",
    "check_duplicates(test1, name=\"Test set\")\n",
    "\n",
    "# Check duplicates for the second input\n",
    "print(\"\\n\\nSECOND data input\")\n",
    "check_duplicates(train2, name=\"Train set\")\n",
    "check_duplicates(test2, name=\"Test set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Merging train1 and train2\n",
    "complete_train = train1.union(train2)\n",
    "\n",
    "# Merging test and labels for the ML part\n",
    "test_df1 = test1.join(label1, on=\"timestamp\", how=\"inner\")\n",
    "test_df2 = test2.join(label2, on=\"timestamp\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Complete dataset: ({complete_train.count()}, {len(complete_train.columns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Complete dataset: ({test_df2.count()}, {len(test_df2.columns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To pandas\n",
    "complete_train_pd = complete_train.toPandas()\n",
    "test_pd1 = test_df1.toPandas()\n",
    "test_pd2 = test_df2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Get the column subset excluding the timestamp column\n",
    "columns_to_exclude = [\"timestamp\", \"label\"]\n",
    "column_subset_test = [col for col in test_pd1.columns if col not in columns_to_exclude]\n",
    "column_subset_all = [col for col in complete_train_pd.columns if col != \"timestamp\"]\n",
    "\n",
    "# Normalization\n",
    "scaled_data = scaler.fit_transform(test_pd1[column_subset_test])\n",
    "scaled_test1 = pd.DataFrame(scaled_data, columns=column_subset_test)\n",
    "scaled_test1.insert(0, \"timestamp\", test_pd1[\"timestamp\"])\n",
    "scaled_test1[\"label\"] = test_pd1[\"label\"]\n",
    "\n",
    "scaled_data = scaler.fit_transform(test_pd2[column_subset_test])\n",
    "scaled_test2 = pd.DataFrame(scaled_data, columns=column_subset_test)\n",
    "scaled_test2.insert(0, \"timestamp\", test_pd2[\"timestamp\"])\n",
    "scaled_test2[\"label\"] = test_pd2[\"label\"]\n",
    "\n",
    "scaled_data = scaler.fit_transform(complete_train_pd[column_subset_all])\n",
    "scaled_complete = pd.DataFrame(scaled_data, columns=column_subset_all)\n",
    "scaled_complete.insert(0, \"timestamp\", complete_train_pd[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving  toCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not processed\n",
    "test_pd1.to_csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/merged_data/test_pd1.csv\", index=False, mode='w')\n",
    "test_pd2.to_csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/merged_data/test_pd2.csv\", index=False, mode='w')\n",
    "complete_train_pd.to_csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/merged_data/complete_pd.csv\", index=False, mode='w')\n",
    "\n",
    "# Processed\n",
    "scaled_test1.to_csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/preprocessed_data/scaled_test1.csv\", index=False, mode='w')\n",
    "scaled_test2.to_csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/preprocessed_data/scaled_test2.csv\", index=False, mode='w')\n",
    "scaled_complete.to_csv(\"/Users/emmatosato/Documents/UNI_Locale/Erasmus/OST/ost-sm-change-detection/data_analysis/preprocessed_data/scaled_complete.csv\", index=False, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting variables distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the distributions of the variables for the different process.\n",
    "The process flow of the testbed was divided into four primary processes: the boiler process (P1), turbine process (P2), water treatment process (P3), and HIL simulation (P4). The label dataset was marked as 1 only when attack occurred to indicate the presence or absence of an attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subplots(data, columns_to_plot, title=\"Train set\", height=900):\n",
    "    fig = make_subplots(rows=len(columns_to_plot), cols=1, subplot_titles=columns_to_plot)\n",
    "\n",
    "    # Plot each time series in a subplot\n",
    "    for i, col in enumerate(columns_to_plot, start=1):\n",
    "        trace = go.Scatter(x=data.index, y=data[col], mode='lines', name=col)\n",
    "        fig.add_trace(trace, row=i, col=1)\n",
    "\n",
    "    # Update layout \n",
    "    fig.update_layout(\n",
    "        title_text=title,\n",
    "        height=height,\n",
    "        template='plotly_white',  \n",
    "        legend=dict(y=1.2),\n",
    "        yaxis=dict(tickmode='linear', tick0=0, dtick=20),\n",
    "    )\n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete train dataset\n",
    "fig1 = plot_subplots(complete_train_pd, [\"P1_FCV01D\", \"P1_PP04SP\", \"P1_LCV01D\", \"P2_24Vdc\", \"P1_TIT01\"], title=\" Process 1\", height=900)\n",
    "fig2 = plot_subplots(complete_train_pd, [\"P2_SIT01\", \"P2_VT01\", \"P2_VTR03\"], title=\"Process 2\", height=900)\n",
    "fig3 = plot_subplots(complete_train_pd, [\"P3_FIT01\", \"P2_VTR03\", \"P3_LIT01\"], title=\"Process3\", height=600)\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test1\n",
    "# fig1 = plot_subplots(test_pd1, [\"P1_FCV01D\", \"P1_PP04SP\", \"P1_LCV01D\", \"P2_24Vdc\", \"P1_TIT01\"], title=\"Test set 1 - Process 1\", height=900)\n",
    "# fig2 = plot_subplots(test_pd1, [\"P2_SIT01\", \"P2_VT01\", \"P2_VTR03\"], title=\"Test set 1 - Process 2\", height=600)\n",
    "# fig3 = plot_subplots(test_pd1, [ \"P3_FIT01\", \"P3_LIT01\"], title= \"Test set 1 - Process 3\", height=400)\n",
    "\n",
    "# fig1.show()\n",
    "# fig2.show()\n",
    "# fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc, callback, Output, Input\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Define the unique titles for each subplot\n",
    "subplot_titles_test1 = [\"Test set 1 - Process 1\", \"Test set 1 - Process 2\", \"Test set 1 - Process 3\"]\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(children='Test set 1 features distributions', style={'textAlign': 'center'}),\n",
    "    dcc.Dropdown(\n",
    "        options=[{'label': title, 'value': title} for title in subplot_titles_test1],\n",
    "        value=subplot_titles_test1[0],\n",
    "        id='dropdown-selection'\n",
    "    ),\n",
    "    dcc.Graph(id='graph-content')\n",
    "])\n",
    "\n",
    "# Define the callback to update the graph based on dropdown selection\n",
    "@app.callback(\n",
    "    Output('graph-content', 'figure'),\n",
    "    [Input('dropdown-selection', 'value')]\n",
    ")\n",
    "def update_graph(selected_title):\n",
    "    # Map selected title to corresponding columns for test_pd1\n",
    "    title_to_columns_test1 = {\n",
    "        \"Test set 1 - Process 1\": [\"P1_FCV01D\", \"P1_PP04SP\", \"P1_LCV01D\", \"P2_24Vdc\", \"P1_TIT01\"],\n",
    "        \"Test set 1 - Process 2\": [\"P2_SIT01\", \"P2_VT01\", \"P2_VTR03\"],\n",
    "        \"Test set 1 - Process 3\": [\"P3_FIT01\", \"P3_LIT01\"]\n",
    "    }\n",
    "\n",
    "    # Get columns based on selected title\n",
    "    columns_to_plot_test1 = title_to_columns_test1.get(selected_title, [])\n",
    "\n",
    "    # Call the plot_subplots function\n",
    "    fig = plot_subplots(test_pd1, columns_to_plot_test1, title=f'{selected_title}')\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test2\n",
    "fig1 = plot_subplots(test_pd2, [\"P1_FCV01D\", \"P1_PP04SP\", \"P1_LCV01D\", \"P2_24Vdc\", \"P1_TIT01\"], title=\"Test set 2 - Process 1\", height=900)\n",
    "fig2 = plot_subplots(test_pd2, [\"P2_SIT01\", \"P2_VT01\", \"P2_VTR03\"], title=\"Test set 1 - Process 2\", height=600)\n",
    "fig3 = plot_subplots(test_pd2, [ \"P3_FIT01\", \"P3_LIT01\"], title= \"Test set 1 - Process 3\", height=400)\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd1[(test_pd1['label'] == 1) & (test_pd1['label'].shift() == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd1[(test_pd1['label'] == 0) & (test_pd1['label'].shift() == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how this variable behave during time (under attack or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_df = complete_train_pd[1500:13000]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "trace = go.Scatter(x=changes_df.index, y=complete_train_pd[\"P1_FCV01D\"], mode='lines', name=\"P1_FCV01D\")\n",
    "fig.add_trace(trace)\n",
    "\n",
    "# Update layout \n",
    "fig.update_layout(\n",
    "    title_text=f\"Changes in P1_FCV01D variable\",\n",
    "    height=500,\n",
    "    template='plotly_white',  \n",
    "    legend=dict(y=1.2),\n",
    "    yaxis=dict(tickmode='linear', tick0=0, dtick=20),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
